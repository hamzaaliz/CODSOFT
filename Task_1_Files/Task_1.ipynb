{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# CodSoft Internship Task: 1\n## Titanic Survival Prediction",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Importing Necessary Libraries",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Importing the necessary libraries.\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "### Loading the datasets into Pandas DataFrames",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Importing the datasets.\ntraining_set = pd.read_csv('train.csv')\ntesting_set = pd.read_csv('test.csv')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "### Cleaning and Preprocessing the Training Set",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Handling missing values in the training set.\ntraining_set['Age'].fillna(training_set['Age'].median(), inplace=True)\ntraining_set['Embarked'].fillna(training_set['Embarked'].mode()[0], inplace=True)\ntraining_set.drop(['Cabin'], axis=1, inplace=True)\n\n# Making suitable data type conversions.\ntraining_set[['Embarked', 'Survived', 'Pclass', 'Sex']] = training_set[['Embarked', 'Survived', 'Pclass', 'Sex']].astype('category')\n\n# Performing feature engineering on the training set, and dropping the columns used to engineer the new feature.\ntraining_set['FamilySize'] = training_set['SibSp'] + training_set['Parch'] + 1\ntraining_set.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n\n# Performing log normalization on the training set to deal with high variances.\ntraining_set['Age'] = np.log(training_set['Age'])\ntraining_set['Fare'] = np.log(training_set['Fare'] + 0.1)\ntraining_set['FamilySize'] = np.log(training_set['FamilySize'])\n\n# Performing one-hot encoding on the categorical columns to convert them into numeric format.\nle = LabelEncoder()\ntraining_set['Sex'] = le.fit_transform(training_set['Sex'])\ntraining_set = pd.get_dummies(training_set, columns=['Pclass', 'Embarked'])\n\n# Performing feature scaling on the training set.\nstandard_scaler = StandardScaler()\ntraining_set[['Age', 'Fare', 'FamilySize']] = standard_scaler.fit_transform(training_set[['Age', 'Fare', 'FamilySize']])\n\n# Performing feature selection by dropping irrelevant columns, and the column to be predicted.\nX_train = training_set.drop(['PassengerId', 'Survived', 'Name', 'Ticket'], axis=1)\ny_train = training_set['Survived']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "### Cleaning and Preprocessing the Testing Set",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Handling missing values in the testing set.\ntesting_set['Age'].fillna(testing_set['Age'].median(), inplace=True)\ntesting_set['Fare'].fillna(testing_set['Fare'].median(), inplace=True)\ntesting_set.drop(['Cabin'], axis=1, inplace=True)\n\n# Making suitable data type conversions.\ntesting_set[['Embarked', 'Pclass', 'Sex']] = testing_set[['Embarked', 'Pclass', 'Sex']].astype('category')\n\n# Performing feature engineering on the testing set, and dropping the columns used to engineer the new feature.\ntesting_set['FamilySize'] = testing_set['SibSp'] + testing_set['Parch'] + 1\ntesting_set.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n\n# Performing log normalization on the testing set to deal with high variances.\ntesting_set['Age'] = np.log(testing_set['Age'])\ntesting_set['Fare'] = np.log(testing_set['Fare'] + 0.1)\ntesting_set['FamilySize'] = np.log(testing_set['FamilySize'])\n\n# Performing one-hot encoding on the categorical columns to convert them into numeric format.\ntesting_set['Sex'] = testing_set['Sex'].map({'male': 1, 'female': 0})\ntesting_set = pd.get_dummies(testing_set, columns=['Pclass', 'Embarked'])\n\n# Performing feature scaling on the testing set.\ntesting_set[['Age', 'Fare', 'FamilySize']] = standard_scaler.transform(testing_set[['Age', 'Fare', 'FamilySize']])\n\n# Performing feature selection by dropping irrelevant columns.\nX_test = testing_set.drop(['PassengerId', 'Name', 'Ticket'], axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "### Making Predictions using SVM Classifier",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# After fine-tuning the model, the SVM classifier is implemented.\nsvm = SVC(gamma=0.1)\n\n# Fit the model to the training data.\nsvm.fit(X_train, y_train)\n\n# Evaluate with cross-validation.\nsvm_cv_scores = cross_val_score(svm, X_train, y_train, cv=5, scoring='accuracy')\n\nprint(\"Tuned SVM CV Accuracy:\", svm_cv_scores.mean())\n\n# Making predictions on the test set.\ny_pred = svm.predict(X_test)\n\n# Printing the first few predictions.\nprint(y_pred[:10])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Tuned SVM CV Accuracy: 0.8226727763480006\n[0 1 0 0 1 0 1 0 1 0]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}